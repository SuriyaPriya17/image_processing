{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJcptYcK7cra0lWoZ6CjL0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SuriyaPriya17/image_processing/blob/main/sift_orb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1GJjyeja5bB"
      },
      "outputs": [],
      "source": [
        "#SIFT\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def build_gaussian_pyramid(image, num_octaves=4, scales_per_octave=5, sigma=1.6):\n",
        "    k = 2**(1/scales_per_octave)\n",
        "    pyramid = []\n",
        "    for o in range(num_octaves):\n",
        "        octave = [image]\n",
        "        for s in range(1, scales_per_octave):\n",
        "            sigma_prev = sigma * (k**(s-1))\n",
        "            sigma_curr = sigma * (k**s)\n",
        "            sigma_diff = np.sqrt(sigma_curr**2 - sigma_prev**2)\n",
        "            blurred = cv2.GaussianBlur(octave[-1], (5, 5), sigmaX=sigma_diff, sigmaY=sigma_diff)\n",
        "            octave.append(blurred)\n",
        "        pyramid.append(octave)\n",
        "        image = cv2.resize(octave[-1], (octave[-1].shape[1] // 2, octave[-1].shape[0] // 2))\n",
        "    return pyramid\n",
        "\n",
        "def build_dog_pyramid(gaussian_pyramid):\n",
        "    dog_pyramid = []\n",
        "    for octave in gaussian_pyramid:\n",
        "        dog = []\n",
        "        for i in range(1, len(octave)):\n",
        "            dog.append(octave[i] - octave[i - 1])\n",
        "        dog_pyramid.append(dog)\n",
        "    return dog_pyramid\n",
        "\n",
        "def detect_keypoints(dog_pyramid, threshold=0.03):\n",
        "    keypoints = []\n",
        "    for o, octave in enumerate(dog_pyramid):\n",
        "        for i in range(1, len(octave) - 1):\n",
        "            prev_img, curr_img, next_img = octave[i-1], octave[i], octave[i+1]\n",
        "            for x in range(1, curr_img.shape[0] - 1):\n",
        "                for y in range(1, curr_img.shape[1] - 1):\n",
        "                    val = curr_img[x, y]\n",
        "                    patch = np.concatenate([\n",
        "                        prev_img[x-1:x+2, y-1:y+2].flatten(),\n",
        "                        curr_img[x-1:x+2, y-1:y+2].flatten(),\n",
        "                        next_img[x-1:x+2, y-1:y+2].flatten()\n",
        "                    ])\n",
        "                    if (val == patch.max() or val == patch.min()) and abs(val) > threshold:\n",
        "                        keypoints.append((x * (2**o), y * (2**o), o))\n",
        "    return keypoints\n",
        "\n",
        "def compute_orientation(image, keypoints):\n",
        "    oriented_keypoints = []\n",
        "    gx = cv2.Sobel(image, cv2.CV_32F, 1, 0, ksize=3)\n",
        "    gy = cv2.Sobel(image, cv2.CV_32F, 0, 1, ksize=3)\n",
        "    magnitude = np.sqrt(gx**2 + gy**2)\n",
        "    angle = np.rad2deg(np.arctan2(gy, gx)) % 360\n",
        "    for x, y, _ in keypoints:\n",
        "        x, y = int(x), int(y)\n",
        "        if 8 < x < image.shape[0]-8 and 8 < y < image.shape[1]-8:\n",
        "            region_mag = magnitude[x-8:x+8, y-8:y+8]\n",
        "            region_ang = angle[x-8:x+8, y-8:y+8]\n",
        "            hist, _ = np.histogram(region_ang, bins=36, range=(0, 360), weights=region_mag)\n",
        "            max_val = hist.max()\n",
        "            peaks = np.where(hist > 0.8 * max_val)[0]\n",
        "            for peak in peaks:\n",
        "                dominant_angle = peak * 10\n",
        "                oriented_keypoints.append((x, y, dominant_angle))\n",
        "    return oriented_keypoints\n",
        "\n",
        "def compute_descriptors(image, keypoints):\n",
        "    gx = cv2.Sobel(image, cv2.CV_32F, 1, 0, ksize=3)\n",
        "    gy = cv2.Sobel(image, cv2.CV_32F, 0, 1, ksize=3)\n",
        "    magnitude = np.sqrt(gx**2 + gy**2)\n",
        "    angle = (np.rad2deg(np.arctan2(gy, gx)) + 360) % 360\n",
        "    descriptors = []\n",
        "    for x, y, orientation in keypoints:\n",
        "        x, y = int(x), int(y)\n",
        "        if x < 8 or y < 8 or x+8 >= image.shape[0] or y+8 >= image.shape[1]:\n",
        "            continue\n",
        "        patch_mag = magnitude[x-8:x+8, y-8:y+8]\n",
        "        patch_ang = (angle[x-8:x+8, y-8:y+8] - orientation) % 360\n",
        "        desc = []\n",
        "        for i in range(0, 16, 4):\n",
        "            for j in range(0, 16, 4):\n",
        "                cell_mag = patch_mag[i:i+4, j:j+4]\n",
        "                cell_ang = patch_ang[i:i+4, j:j+4]\n",
        "                hist, _ = np.histogram(cell_ang, bins=8, range=(0, 360), weights=cell_mag)\n",
        "                desc.extend(hist)\n",
        "        desc = np.array(desc)\n",
        "        descriptors.append(desc)\n",
        "    return np.array(descriptors)\n",
        "\n",
        "def sift_features(image_path):\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    gaussian_pyramid = build_gaussian_pyramid(img)\n",
        "    dog_pyramid = build_dog_pyramid(gaussian_pyramid)\n",
        "    keypoints = detect_keypoints(dog_pyramid)\n",
        "    oriented_keypoints = compute_orientation(img, keypoints)\n",
        "    descriptors = compute_descriptors(img, oriented_keypoints)\n",
        "    print(\"Total keypoints detected:\", len(oriented_keypoints))\n",
        "    return oriented_keypoints, descriptors\n",
        "\n",
        "image_path = \"sample.jpeg\"\n",
        "kps, desc = sift_features(image_path)\n",
        "img = cv2.imread(image_path)\n",
        "for (x, y, ang) in kps:\n",
        "    cv2.circle(img, (int(y), int(x)), 2, (0, 255, 0), 1)\n",
        "cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import math\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def detect_keypoints(image, threshold=30):\n",
        "    h, w = image.shape\n",
        "    keypoints = []\n",
        "    offsets = np.array([\n",
        "        (0, -3), (1, -3), (2, -2), (3, -1),\n",
        "        (3, 0), (3, 1), (2, 2), (1, 3),\n",
        "        (0, 3), (-1, 3), (-2, 2), (-3, 1),\n",
        "        (-3, 0), (-3, -1), (-2, -2), (-1, -3)\n",
        "    ])\n",
        "    for y in range(3, h-3):\n",
        "        for x in range(3, w-3):\n",
        "            center = int(image[y, x]) # Cast to int to prevent overflow\n",
        "            circle = np.array([int(image[y+dy, x+dx]) for dx, dy in offsets]) # Cast to int to prevent overflow\n",
        "            brighter = np.sum(circle > center + threshold)\n",
        "            darker = np.sum(circle < center - threshold)\n",
        "            if brighter >= 12 or darker >= 12:\n",
        "                keypoints.append((x, y))\n",
        "    return keypoints\n",
        "\n",
        "def compute_orientation(image, keypoints, patch_size=31):\n",
        "    orientations = []\n",
        "    half = patch_size // 2\n",
        "    for (x, y) in keypoints:\n",
        "        if x < half or y < half or x >= image.shape[1]-half or y >= image.shape[0]-half:\n",
        "            orientations.append(0)\n",
        "            continue\n",
        "\n",
        "        patch = image[y-half:y+half+1, x-half:x+half+1]\n",
        "        total_pixel_sum = np.sum(patch)\n",
        "        if total_pixel_sum == 0:\n",
        "            orientations.append(0)\n",
        "            continue\n",
        "\n",
        "        # Corrected moment calculations for orientation\n",
        "        m10 = np.sum(np.arange(-half, half+1) * np.sum(patch, axis=0))\n",
        "        m01 = np.sum(np.arange(-half, half+1)[:, np.newaxis] * np.sum(patch, axis=1)[:, np.newaxis])\n",
        "\n",
        "        angle = math.atan2(m01, m10)\n",
        "        orientations.append(angle)\n",
        "    return orientations\n",
        "\n",
        "def generate_brief_descriptors(image, keypoints, orientations, patch_size=31, n_bits=256):\n",
        "    np.random.seed(42)\n",
        "    half = patch_size // 2\n",
        "    pattern = np.random.randint(-half, half, (n_bits, 4))\n",
        "    descriptors = []\n",
        "    h, w = image.shape\n",
        "    for (x, y), theta in zip(keypoints, orientations):\n",
        "        if x < half or y < half or x >= w - half or y >= h - half:\n",
        "            descriptors.append(np.zeros(n_bits, dtype=np.uint8))\n",
        "            continue\n",
        "        cos_t, sin_t = np.cos(theta), np.sin(theta)\n",
        "        desc = np.zeros(n_bits, dtype=np.uint8)\n",
        "        for i, (x1, y1, x2, y2) in enumerate(pattern):\n",
        "            xr1 = int(x1 * cos_t - y1 * sin_t)\n",
        "            yr1 = int(x1 * sin_t + y1 * cos_t)\n",
        "            xr2 = int(x2 * cos_t - y2 * sin_t)\n",
        "            yr2 = int(x2 * sin_t + y2 * cos_t)\n",
        "\n",
        "            # Boundary checks\n",
        "            final_y1 = y + yr1\n",
        "            final_x1 = x + xr1\n",
        "            final_y2 = y + yr2\n",
        "            final_x2 = x + xr2\n",
        "\n",
        "            if final_y1 < 0 or final_y1 >= h or final_x1 < 0 or final_x1 >= w or \\\n",
        "               final_y2 < 0 or final_y2 >= h or final_x2 < 0 or final_x2 >= w:\n",
        "                desc[i] = 0\n",
        "            else:\n",
        "                p1 = image[final_y1, final_x1]\n",
        "                p2 = image[final_y2, final_x2]\n",
        "                desc[i] = 1 if p1 < p2 else 0\n",
        "        descriptors.append(desc)\n",
        "    return np.array(descriptors, dtype=np.uint8)\n",
        "\n",
        "def orb_feature_extraction(image):\n",
        "    image = cv2.GaussianBlur(image, (5, 5), 1.2)\n",
        "    keypoints = detect_keypoints(image)\n",
        "    orientations = compute_orientation(image, keypoints)\n",
        "    descriptors = generate_brief_descriptors(image, keypoints, orientations)\n",
        "    return keypoints, descriptors\n",
        "\n",
        "image = cv2.imread('sample.jpeg', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "keypoints, descriptors = orb_feature_extraction(image)\n",
        "\n",
        "output = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
        "for (x, y) in keypoints:\n",
        "    cv2.circle(output, (x, y), 2, (0, 255, 0), 1)\n",
        "\n",
        "cv2_imshow(output)\n",
        "#cv2.waitKey(0)\n",
        "#cv2.destroyAllWindows()\n",
        "print(f\"Extracted {len(keypoints)} keypoints\")\n"
      ],
      "metadata": {
        "id": "21MVPGd1qp5g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}